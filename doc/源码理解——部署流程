java SparkSubmit -xxx -xxxx -xxx
会产生一个进程

JVM - Process(SparkSubmit) - main
比如：我们在centos进行spark-shell就会产生一个SparkSubmit


        <!-- spark yarn 阅读源码时需要依赖进行查看 -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-yarn_2.11</artifactId>
            <version>2.1.1</version>
        </dependency>


SparkSubmit.scala文件
所属包名：org.apache.spark.deploy

1、SparkSubmit
    // 启动进程
    -- main

        // 封装参数
        -- new SparkSubmitArguments --> handle()
            // isYarnCluster
            -- childMainClass = "org.apache.spark.deploy.yarn.Client" // 需要导入spark-yarn pom依赖
            // Client
            -- childMainClass = args.mainClass (SparkPi)

        -- doRunMain(runMain)
            // 反射加载类
            -- Utils.classForName(childMainClass)
            // 查找main方法
            --  mainClass.getMethod("main", new Array[String](0).getClass)
            // 调用main方法
            -- mainMethod.invoke


2、Client
    -- main

        -- new ClientArguments(argStrings)

        -- new Client
            -- yarnClient = YarnClient.createYarnClient

        -- client.run
            -- submitApplication
                // 封装指令 command = bin/java org.apache.spark.deploy.yarn.ApplicationMaster (Cluster)
                    Client模式
                    command = bin/java org.apache.spark.deploy.yarn.ExecutorLauncher
                -- createContainerLaunchContext

                -- createApplicationSubmissionContext

                // 向Yarn提交应用，提交指令
                -- yarnClient.submitApplication(appContext)



Client发送运行指令到RM，在nodemanger中选一台启动ApplicationMaster
3、ApplicationMaster
    // 启动进程
    -- main

        // 创建应用管理器对象
        -- new ApplicationMaster(amArgs, new YarnRMClient)
        -- new ApplicationMaster
        // 运行
        -- master.run
            // Cluster
            -- runDriver
                // 启动用户应用
                -- startUserApplication
                    // 获取用户应用的类的main方法
                    -- userClassLoader.loadClass(args.userClass)
                          .getMethod("main", classOf[Array[String]])
                    // 启动Driver线程，执行用户类的main方法
                    -- new Thread().start()
                // 注册AM
                -- registerAM
                    // 获取yarn资源
                    -- client.register
                    // 分配资源
                    -- allocator.allocateResources()

                        -- handleAllocatedContainers

                            -- runAllocatedContainers

                                -- new ExecutorRunnable().run

                                    -- startContainer
                                        // command = bin/java
                                        org.apache.spark.executor.CoarseGrainedExecutorBackend (在NodeManager启动ExecutorBackend)
                                        -- prepareCommand

4.CoarseGrainedExecutorBackend
    -- main
        -- run
            ### ThreadSafeRpcEndpoint / RpcEndpoint / constructor -> onStart -> receive* -> onStop
            -- onStart
                -- ref.ask[Boolean](RegisterExecutor())

            -- receive
                -- case RegisteredExecutor


Spark中特殊的类
Backend：后台
rpcEnv: RPC，早期叫IPC(IPC进程调进程)，不同机器之间远程调用RPC，是一套规范
amEndpoint: 终端
RpcEndpointAddress：终端地址


====
查看抽象类的实现类
Navigate -> Call Hierarchy

Spark 通迅架构
Spark2.x版本使用Netty通讯框架作为内部通讯组件。spark 基于netty新的rpc框架借鉴了Akka的中的设计，它是基于Actor模型
源码位置：
CoarseGrainedExecutorBackend
    -- run
        -- env.rpcEnv.setupEndpoint() -- // RpcEnv.scala接口由 (NettyRpcEnv.scala实现setupEndpoint方法) 【CoarseGrainedExecutorBackend.scala】
            // dispatcher 调度器注册终端
            -- dispatcher.registerRpcEndpoint(name, endpoint)  【NettyRpcEnv.scala】
                -- new NettyRpcEndpointRef() // nettyRpc终端引用，会注册收件箱，同时给自己的收件箱发一条OnStart指令
                            -- endpoints  // ConcurrentHashMap 16个小格子，每个小格子都有自己的一把锁，提高并发度。默认并发度16
                              private class EndpointData(
                                  val name: String,
                                  val endpoint: RpcEndpoint,
                                  val ref: NettyRpcEndpointRef) {
                                val inbox = new Inbox(ref, endpoint) // InBox收件箱
                              }
                                // 【Inbox.scala】
                                --   inbox.synchronized { // 收件箱注册完后，马上给自己发一条onStart消息，完成EndPoint一次生命周期
                                       messages.add(OnStart) // CoarseGrainedExecutorBackend.scala 226行给Executor发了一条onStart消息。相当于env.rpcEnv.setupEndpoint("Executor", new CoarseGrainedExecutorBackend
                                     }
                                -- Inbox.process(dispatcher: Dispatcher) // 处理收件箱中的消息

                -- onStart() 被触发 // 【CoarseGrainedExecutorBackend.scala】
                    -- ref.ask[Boolean](RegisterExecutor() // 向driver反向注册Executor，接着driver就会收到此消息

SparkContext.scala
    -- SchedulerBackend负责后台消息的接收处理 由【CoarseGrainedSchedulerBackend.scala】实现
    -- CoarseGrainedSchedulerBackend 中有：onStart、receive等消息处理方法
        -- receiveAndReply() // 处理收件箱中的消息，比如刚刚的 "RegisterExecutor"消息
          -- executorRef.send(RegisteredExecutor) // 在driver中持有的executor引用对象，向executor发送已注册成功的消息

        RpcEnv.scala





















